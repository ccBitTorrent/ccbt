---
globs: tests/**/*.py
description: Testing patterns and requirements for ccBitTorrent
---

# Testing Patterns

### Testing Requirements
- **Coverage targets**: Project 99% (Codecov), Patch 90%
- **Unit tests** for all functions/methods
- **Integration tests** for component workflows
- **Property-based tests** for algorithms with Hypothesis
- **Performance tests** using pytest-benchmark
- **Chaos tests** for resilience and fault tolerance

### Suite Layout
Tests live in `tests/` and are organized by domain:
- `tests/unit/` with subpackages: `core/`, `disk/`, `file/`, `metadata/`, `network/`, `peer/`, `piece/`, `resilience/`, `session/`, `tracker/`
- `tests/integration/`
- `tests/property/`
- `tests/performance/`
- `tests/chaos/`
- `tests/extensions/`, `tests/protocols/`, `tests/monitoring/`, `tests/observability/`, `tests/plugins/`, `tests/ml/`, `tests/cli/`, `tests/config/`
- Shared config/fixtures in `tests/conftest.py`

### Pytest Configuration
- Markers (from `pytest.ini` / `pyproject.toml`):
  - `asyncio`, `slow`, `timeout`, `integration`, `unit`, `core`, `peer`, `piece`, `tracker`, `network`, `metadata`, `disk`, `file`, `session`, `resilience`, `connection`, `checkpoint`, `cli`
- Async mode: `asyncio_mode = auto`
- Default addopts (CI/coverage runs, from `pyproject.toml`):
  - `--cov=ccbt --cov-report=term-missing --cov-report=html --cov-report=xml`

### Core Test Fixtures and Hygiene
Defined in `tests/conftest.py`:
- Global logging handler cleanup after each test (prevents closed-file I/O errors)
- Async resource cleanup: cancel and gather pending tasks, yield to loop
- Per-test event loop via `event_loop` fixture
- Deterministic RNG seeding (env `CCBT_TEST_SEED`, defaults to 123456); optional NumPy support
- `tmp_storage` fixture for temp file/disk operations

### Running Tests
- Full suite: `uv run pytest -v`
- By marker: `uv run pytest -m "unit and not slow"`
- With coverage (local): `uv run pytest --cov=ccbt --cov-report=term-missing --cov-report=xml`
- Timeouts: default 300s per test (`--timeout=300 --timeout-method=thread` in hooks). Coverage hook uses 600s.

### Selective Test Execution (Pre-commit)
Pre-commit runs selective tests via `tests/scripts/run_pytest_selective.py`:
- Maps changed `ccbt/` files to markers using `tests/scripts/get_test_markers.py`
- Marker mapping derives from `.codecov.yml` flags → paths
- Critical files (`pytest.ini`, `.codecov.yml`, `.pre-commit-config.yaml`, `tests/conftest.py`, `ccbt/config.py`) force running the entire suite
- Regular hook: `-v --tb=short --maxfail=5 --timeout=300 --timeout-method=thread`
- Coverage hook (pre-push): `--cov=ccbt --cov-report=term-missing --cov-report=xml --cov-fail-under=40 --timeout=600 --timeout-method=thread`

### Coverage and Codecov
- CI targets in `.codecov.yml`: project 99% (±1%), patch 90% (±2%)
- Flags categorize coverage by domain. Ensure paths reflect real modules:
  - Example corrections: use `ccbt/peer/`, `ccbt/piece/`, `ccbt/protocols/`, etc., rather than single-file roots
- Local HTML/XML reports are enabled via pytest addopts; artifacts used by Codecov

### Async Testing Pattern
```python
import pytest

@pytest.mark.asyncio
async def test_async_operation():
    result = await some_async_fn()
    assert result is not None
```

### Property-Based Testing
```python
from hypothesis import given, strategies as st

@given(st.binary())
def test_bencode_roundtrip(data: bytes) -> None:
    encoded = ccbt.core.bencode.encode(data)
    decoded = ccbt.core.bencode.decode(encoded)
    assert decoded == data
```

### Performance Testing
```python
def test_performance(benchmark):
    result = benchmark(target_function)
    assert result is not None  # add domain-specific threshold if applicable
```

### Chaos and Resilience Testing
- Fault injection and resilience under timeouts in `tests/chaos/` and `tests/unit/resilience/`
- Use markers `chaos`/`resilience` and thread-based timeouts to avoid event-loop deadlocks

### CLI and Docs Hooks (Pre-commit)
- Lint: `uv run ruff check ccbt/ --fix`
- Format: `uv run ruff format ccbt/`
- Type check: `uv run ty check --config-file=ty.toml`
- Security: `uv run bandit -r ccbt/ -f json -o bandit-report.json --exclude tests/`
- Tests: `uv run python tests/scripts/run_pytest_selective.py`
- Coverage (pre-push): `uv run python tests/scripts/run_pytest_selective.py --coverage`
- Docs: `uv run mkdocs build --strict`

### Expectations for New Tests
- Include unit tests for new functions and methods
- Add integration tests when behavior spans multiple services/components
- Add property tests for serialization, selection, or algorithmic logic
- Add performance tests for optimizations or critical paths
- Respect markers and directory conventions to integrate with selective runs
- Keep tests deterministic (use provided fixtures), avoid uncontrolled sleeps


